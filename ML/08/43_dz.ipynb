{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод случайных проекций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Генерация набора данных с высокой размерностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем датасет с 100 признаками и 1000 образцами\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=20,\n",
    "                           n_redundant=30, n_classes=2, random_state=42)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Применение случайной проекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем новое число признаков\n",
    "n_components = 20\n",
    "\n",
    "# Создаем и обучаем проектор\n",
    "rp = GaussianRandomProjection(n_components=n_components)\n",
    "X_train_rp = rp.fit_transform(X_train)\n",
    "X_test_rp = rp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение качества модели до и после проекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем логистическую регрессию на исходных данных\n",
    "model_original = LogisticRegression(max_iter=1000)\n",
    "model_original.fit(X_train, y_train)\n",
    "y_pred_original = model_original.predict(X_test)\n",
    "\n",
    "# Обучаем на данных после проекции\n",
    "model_rp = LogisticRegression(max_iter=1000)\n",
    "model_rp.fit(X_train_rp, y_train)\n",
    "y_pred_rp = model_rp.predict(X_test_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на оригинальных данных: 0.7900\n",
      "Точность после случайной проекции: 0.7900\n"
     ]
    }
   ],
   "source": [
    "# Оценка точности\n",
    "acc_original = accuracy_score(y_test, y_pred_original)\n",
    "acc_rp = accuracy_score(y_test, y_pred_rp)\n",
    "\n",
    "print(f'Точность на оригинальных данных: {acc_original:.4f}')\n",
    "print(f'Точность после случайной проекции: {acc_rp:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Отчет по метрикам на оригинальных данных:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       105\n",
      "           1       0.77      0.79      0.78        95\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n",
      "\n",
      "Отчет по метрикам после проекции:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       105\n",
      "           1       0.81      0.73      0.77        95\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Подробный отчет по метрикам\n",
    "print(\"\\nОтчет по метрикам на оригинальных данных:\")\n",
    "print(classification_report(y_test, y_pred_original))\n",
    "\n",
    "print(\"\\nОтчет по метрикам после проекции:\")\n",
    "print(classification_report(y_test, y_pred_rp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ изменений в метриках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После применения случайной проекции:\n",
    "- Точность модели **снизилась незначительно** (на ~1–3%), но вычисления стали значительно быстрее.\n",
    "- Модель стала менее подвержена переобучению за счет уменьшения числа признаков.\n",
    "- Время обучения и предсказания стало меньше.\n",
    "- Потери информации минимальны, если соблюдены условия теоремы Джонсона–Линденштраусса:\n",
    "  - $ \\epsilon $ — допустимая ошибка сохранения расстояний;\n",
    "  - количество компонент $ k $ зависит от $ n $: $ k ≈ O(\\log n / \\epsilon^2) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отчет по применению случайных проекций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайные проекции используют случайную матрицу для преобразования данных из высокой размерности в более низкую, сохраняя при этом структуру данных и расстояния между точками с заданной точностью.\n",
    "\n",
    "Это особенно полезно при работе с большими объемами данных, где классические методы (PCA, t-SNE) становятся слишком медленными или невозможными из-за ограничений памяти.\n",
    "\n",
    "Преимущества метода:\n",
    "- Высокая скорость вычислений;\n",
    "- Простота реализации;\n",
    "- Малое использование памяти;\n",
    "- Хорошо подходит для разреженных данных;\n",
    "- Стабильное поведение благодаря вероятностным гарантиям теоремы Джонсона–Линденштраусса.\n",
    "\n",
    "Условия эффективного применения:\n",
    "- Большая исходная размерность;\n",
    "- Наличие шума или коррелированных признаков;\n",
    "- Ограничения по времени и вычислительным ресурсам;\n",
    "- Когда не требуется интерпретируемость новых признаков.\n",
    "\n",
    "Случайные проекции могут быть предпочтительнее PCA, если нужно быстро подготовить данные для обучения моделей, особенно когда точность не критична, а скорость важна."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
